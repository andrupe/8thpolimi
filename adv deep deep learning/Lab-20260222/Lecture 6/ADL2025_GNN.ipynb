{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Learning on Graphs\n",
        "\n",
        "This tutorial is based on the material of Stanford class [CS224W](https://web.stanford.edu/class/cs224w/index.html)"
      ],
      "metadata": {
        "id": "c_28wKoKsbjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graphs with networkx and Pytorch geometric"
      ],
      "metadata": {
        "id": "t5e8oq5rJ-oX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As usual, some installations and imports. This may take a while:"
      ],
      "metadata": {
        "id": "7g5jnmxDKCJG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZvq83o-H01C"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import SGD\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# Install torch geometric\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
        "!pip install -q torch-geometric\n",
        "\n",
        "!pip install git+https://github.com/snap-stanford/ogb.git\n",
        "\n",
        "from torch_geometric.datasets import KarateClub\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and examine Zachary's Karate Club Network with networkx"
      ],
      "metadata": {
        "id": "gfjtpisAOSwf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NetworkX is one of the most frequently used Python packages to create, manipulate, and mine graphs.\n",
        "\n",
        "The Karate Club Network is a graph which describes a social network of 34 members of a karate club and documents links between members who interacted outside the club."
      ],
      "metadata": {
        "id": "6tx-fXFVKJpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.karate_club_graph()\n",
        "\n",
        "# G is an undirected graph\n",
        "type(G)"
      ],
      "metadata": {
        "id": "6MXv78E-KKTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the graph\n",
        "nx.draw(G, with_labels = True)"
      ],
      "metadata": {
        "id": "0gR6iW3AKQaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at a node\n",
        "nodes = G.nodes(data=True)\n",
        "nodes[0]"
      ],
      "metadata": {
        "id": "49N7lXWpKkTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many nodes in the graph? How many edges?\n",
        "N = G.number_of_nodes()\n",
        "E = G.number_of_edges()\n",
        "print(N, \" nodes, \", E, \" edges\")"
      ],
      "metadata": {
        "id": "AaI9nYRzLXdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at an edge\n",
        "edges = G.edges\n",
        "ij = (0, 11)\n",
        "if ij in edges:\n",
        "  print(edges[ij])\n",
        "else:\n",
        "  print(\"Not in the graph\")"
      ],
      "metadata": {
        "id": "QFrzQKMQLyrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Degree\n",
        "node_id = 0\n",
        "G.degree(node_id)"
      ],
      "metadata": {
        "id": "58QLmtxKMQX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neighbors\n",
        "node_id = 0\n",
        "list(G.neighbors(node_id))"
      ],
      "metadata": {
        "id": "IaKok5W3N_pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qywlcjyr8USw"
      },
      "outputs": [],
      "source": [
        "# Visualization function  for NX graph or PyTorch tensor\n",
        "def visualize(h, color, epoch=None, loss=None, accuracy=None):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    if torch.is_tensor(h):\n",
        "        h = h.detach().cpu().numpy()\n",
        "        plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
        "    else:\n",
        "        nx.draw_networkx(h, pos=nx.spring_layout(h, seed=42), with_labels=False,\n",
        "                         node_color=color, cmap=\"Set2\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pytorch Geometric"
      ],
      "metadata": {
        "id": "Pn2msC2SWL63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = KarateClub()\n",
        "dataset = KarateClub()\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')"
      ],
      "metadata": {
        "id": "oYPQJxH6P-uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each graph in PyTorch Geometric is represented by a single [`Data`](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data) object, which holds all the information to describe its graph representation."
      ],
      "metadata": {
        "id": "hJssCJl4W_Xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataset[0]  # Get the first graph object.\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "id": "vTSdZHOFW0_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `edge_index` property holds the information about the **graph connectivity**, *i.e.*, a tuple of source and destination node indices for each edge.\n",
        "PyG further refers to **node features** as `x` (each of the 34 nodes is assigned a 34-dim feature vector), and to **node labels** as `y` (each node is assigned to exactly one class)."
      ],
      "metadata": {
        "id": "6SZis_TMXFdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gather some statistics about the graph.\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Average node degree: {(data.num_edges) / data.num_nodes:.2f}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "print(f'Contains isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Contains self-loops: {data.has_self_loops()}')\n",
        "print(f'Is undirected: {data.is_undirected()}')"
      ],
      "metadata": {
        "id": "gGHJXyjKUdUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adjacency list:"
      ],
      "metadata": {
        "id": "HFw9iBjwXm6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edges = data.edge_index\n",
        "print(edges.T)"
      ],
      "metadata": {
        "id": "GHV0zu3dXbqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This representation is known as the **COO format (coordinate format)** commonly used for representing sparse matrices.\n",
        "Instead of holding the adjacency information in a dense representation $\\mathbf{A} \\in \\{ 0, 1 \\}^{|\\mathbb{V}| \\times |\\mathbb{V}|}$, PyG represents graphs sparsely, which refers to only holding the coordinates/values for which entries in $\\mathbf{A}$ are non-zero."
      ],
      "metadata": {
        "id": "hv_-0ENtXwcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From geometric to networkx\n",
        "data_G = to_networkx(data, to_undirected=True)\n",
        "visualize(data_G, color=data.y)"
      ],
      "metadata": {
        "id": "_SKaJMXoWgCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node Embeddings\n",
        "\n",
        "In this section we will learn some shallow embeddings for the nodes of the Karate graph"
      ],
      "metadata": {
        "id": "n804zRPVYMcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "def seed_everything(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "seed_everything(seed)"
      ],
      "metadata": {
        "id": "bJtol6DGZwid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start with randomly initialized 16-dimensional embeddings (one for each node)"
      ],
      "metadata": {
        "id": "jUdFWct-v3cU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 34 16-dimensional embeddings:\n",
        "emb = nn.Embedding(num_embeddings=34, embedding_dim=16)\n",
        "print(emb.weight.data.shape)\n",
        "\n",
        "# Initialize with uniform([0,1))\n",
        "emb.weight.data = torch.rand(size=emb.weight.data.shape)"
      ],
      "metadata": {
        "id": "xApduLTPXvti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select an embedding in emb_sample\n",
        "id = torch.LongTensor([1])\n",
        "print(emb(id))"
      ],
      "metadata": {
        "id": "cftdPWavwHIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select multiple embeddings\n",
        "ids = torch.LongTensor([1, 3])\n",
        "print(emb(ids))"
      ],
      "metadata": {
        "id": "P2WD3zMewH2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can visualize the embedding in 2D using PCA.\n",
        "\n",
        "The node attribute \"club\" tells us which club the member joined after the original club split."
      ],
      "metadata": {
        "id": "_Art13_JaTTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_emb(emb):\n",
        "  X = emb.weight.data.numpy()\n",
        "  pca = PCA(n_components=2)\n",
        "  components = pca.fit_transform(X)\n",
        "  plt.figure(figsize=(6, 6))\n",
        "  club1_x = []\n",
        "  club1_y = []\n",
        "  club2_x = []\n",
        "  club2_y = []\n",
        "  for node in G.nodes(data=True):\n",
        "    if node[1]['club'] == 'Mr. Hi':\n",
        "      club1_x.append(components[node[0]][0])\n",
        "      club1_y.append(components[node[0]][1])\n",
        "    else:\n",
        "      club2_x.append(components[node[0]][0])\n",
        "      club2_y.append(components[node[0]][1])\n",
        "  plt.scatter(club1_x, club1_y, color=\"red\", label=\"Mr. Hi\")\n",
        "  plt.scatter(club2_x, club2_y, color=\"blue\", label=\"Officer\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "# Visualize the initial random embeddding\n",
        "visualize_emb(emb)"
      ],
      "metadata": {
        "id": "-f_AMwyaYgLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to fit a (logistic regression) classifier to predict the club from the node embeddings:"
      ],
      "metadata": {
        "id": "CZRZsyvUbiUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = emb.weight.detach().numpy()\n",
        "y = np.zeros(X.shape[0])\n",
        "for i in range(G.number_of_nodes()):\n",
        "  y[i] = G.nodes[i]['club'] == 'Mr. Hi'\n",
        "\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X[:27], y[:27])\n",
        "clf.score(X[27:], y[27:])"
      ],
      "metadata": {
        "id": "0_MVuC4dG9PH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will take a **random walk** view, which will be useful later...\n",
        "\n",
        "We train the embedding to maximize the likelihood that **similar** nodes are neighbors in a 1-step random walk on the graph, using dot product as our measure of similarity:\n",
        "\n",
        "$\\mathcal{L} = -\\sum_{u\\in V}\\sum_{v\\in\\mathrm{neighbors(u)}} \\log P(v | u) = -\\sum_{u\\in V}\\sum_{v\\in\\mathrm{neighbors(u)}} \\log \\left(\\frac{\\exp(z_u^Tz_v)}{\\sum_{n\\in V}\\exp(z_u^Tz_n)}\\right)$"
      ],
      "metadata": {
        "id": "bxVswerJyuXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is approximated by minimizing **binary cross entropy loss** with positive examples (actual neighbors) and negative examples (randomly sampled \"non neighbors\" $n_i$)"
      ],
      "metadata": {
        "id": "vlS58FUDZakr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\mathcal{L} \\simeq -\\sum_{u\\in V}\\sum_{v\\in\\mathrm{neighbors(u)}} \\log(\\sigma(z_u^Tz_v)) -\\sum_{u\\in V}\\sum_{i=1}^N \\log(1-\\sigma(z_u^Tz_{n_i}))$"
      ],
      "metadata": {
        "id": "BJPYySZsZxIQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate positive examples (the edges of the graph)"
      ],
      "metadata": {
        "id": "53MlUm2myiJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positive_samples_adj(G):\n",
        "  edge_list = []\n",
        "  for edge in G.edges():\n",
        "    edge_list.append(edge)\n",
        "\n",
        "  edge_index = torch.tensor(edge_list).T\n",
        "  return edge_index\n",
        "\n",
        "pos_edge_index = positive_samples_adj(G)\n",
        "pos_edge_index.shape"
      ],
      "metadata": {
        "id": "N--2YVtWuFRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate negative examples (n pairs of nodes that do not share an edge in the graph)"
      ],
      "metadata": {
        "id": "iPaHtoUhykZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def negative_samples(G, n):\n",
        "  neg_edge_list = []\n",
        "\n",
        "  edge_set = set()\n",
        "  for edge in G.edges():\n",
        "    edge_set.add(edge)\n",
        "\n",
        "  nodes = list(G.nodes)\n",
        "  for i, node1 in enumerate(nodes):\n",
        "      for node2 in nodes[i+1:]:\n",
        "          if (node1, node2) not in edge_set:\n",
        "            neg_edge_list.append((node1, node2))\n",
        "  neg_edge_list = random.sample(neg_edge_list, n)\n",
        "  edge_index = torch.tensor(neg_edge_list).T\n",
        "  return edge_index\n",
        "\n",
        "neg_edge_index = negative_samples(G, 78)\n",
        "neg_edge_index.shape"
      ],
      "metadata": {
        "id": "myyv29EtymjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(pred, label):\n",
        "  return torch.sum(torch.round(pred) == label) / pred.shape[0]\n",
        "\n",
        "def train(emb, loss_fn, train_label, train_edge,\n",
        "          epochs=500,\n",
        "          learning_rate=0.1):\n",
        "  optimizer = SGD(emb.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "  for i in range(epochs):\n",
        "    sigmoid = nn.Sigmoid()\n",
        "    optimizer.zero_grad()\n",
        "    node_emb = emb(train_edge)\n",
        "    dot_product = torch.sum(node_emb[0] * node_emb[1], -1)\n",
        "    result = sigmoid(dot_product)\n",
        "    loss = loss_fn(result, train_label)\n",
        "    print(\"Epoch:\", i, \"Loss:\", loss.item(),\n",
        "          \"Acc:\", accuracy(result, train_label).item())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  return emb"
      ],
      "metadata": {
        "id": "ikzM09SwaVsN",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "pos_edge_index = positive_samples_adj(G)\n",
        "neg_edge_index = negative_samples(G, n=pos_edge_index.shape[1])\n",
        "\n",
        "# Generate the positive and negative labels\n",
        "pos_label = torch.ones(pos_edge_index.shape[1], )\n",
        "neg_label = torch.zeros(neg_edge_index.shape[1], )\n",
        "\n",
        "# Concat positive and negative labels into one tensor\n",
        "train_label = torch.cat([pos_label, neg_label], dim=0)\n",
        "n = len(train_label)\n",
        "\n",
        "# Concat positive and negative edges into one tensor\n",
        "# Since the network is very small, we do not split the edges into val/test sets\n",
        "train_edge = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
        "\n",
        "# Shuffle\n",
        "perm = torch.randperm(n)\n",
        "train_edge = train_edge[:, perm]\n",
        "train_label = train_label[perm]\n",
        "\n",
        "train(emb, loss_fn, train_label, train_edge)"
      ],
      "metadata": {
        "id": "gvLwUdrs895E",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize learned embeddings\n",
        "visualize_emb(emb)"
      ],
      "metadata": {
        "id": "D3GcuTsC2A5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, let's try to fit a (logistic regression) classifier to predict the club from the node embeddings:"
      ],
      "metadata": {
        "id": "5WupZ0u1bvtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = emb.weight.detach().numpy()\n",
        "y = np.zeros(X.shape[0])\n",
        "for i in range(G.number_of_nodes()):\n",
        "  y[i] = G.nodes[i]['club'] == 'Mr. Hi'\n",
        "\n",
        "clf = LogisticRegression(random_state=0).fit(X[:27], y[:27])\n",
        "clf.score(X[27:], y[27:])"
      ],
      "metadata": {
        "id": "mD_GSkpkHCEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO:** RANDOM WALK\n",
        "\n",
        "Using the negative sampling approach described above, learn a 16-dimensional node embedding based on **first-order unbiased random walks**.\n",
        "\n",
        "To generate the positive examples, simulate a random walk from each node $u$ in the graph. Start from $u$ and continue the walk by selecting a neighbor of the current node uniformly at random. Every node $v_i$ visited along the walk provides a positive example $(u, v_i)$.\n",
        "\n",
        "You can generate negative examples at random as before."
      ],
      "metadata": {
        "id": "MPtCuxDB6ZiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement this function to generate positive examples\n",
        "# The function takes the graph, the length of walks, and the number of walks to simulate from each node of the graph\n",
        "def positive_samples_fo(G, length=5, n_walks=10):\n",
        "  # YOUR CODE HERE\n",
        "  return ..."
      ],
      "metadata": {
        "id": "8dmt2N0R5mhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_2 = nn.Embedding(num_embeddings=G.number_of_nodes(), embedding_dim=16)\n",
        "emb_2.weight.data = torch.rand(size=emb_2.weight.data.shape)\n",
        "\n",
        "pos_edge_index = positive_samples_fo(G, length=5, n_walks=10)\n",
        "neg_edge_index = negative_samples(G, n=300)\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "# Generate the positive and negative labels\n",
        "pos_label = torch.ones(pos_edge_index.shape[1], )\n",
        "neg_label = torch.zeros(neg_edge_index.shape[1], )\n",
        "\n",
        "# Concat positive and negative labels into one tensor\n",
        "train_label = torch.cat([pos_label, neg_label], dim=0)\n",
        "n = len(train_label)\n",
        "\n",
        "# Concat positive and negative edges into one tensor\n",
        "# Since the network is very small, we do not split the edges into val/test sets\n",
        "train_edge = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
        "\n",
        "# Shuffle\n",
        "perm = torch.randperm(n)\n",
        "train_edge = train_edge[:, perm]\n",
        "train_label = train_label[perm]\n",
        "\n",
        "train(emb_2, loss_fn, train_label, train_edge)\n",
        "\n",
        "visualize_emb(emb_2)"
      ],
      "metadata": {
        "id": "YAKNYIiT8_tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = emb_2.weight.detach().numpy()\n",
        "y = np.zeros(X.shape[0])\n",
        "for i in range(G.number_of_nodes()):\n",
        "  y[i] = G.nodes[i]['club'] == 'Mr. Hi'\n",
        "\n",
        "clf = LogisticRegression(random_state=0).fit(X[:27], y[:27])\n",
        "clf.score(X[27:], y[27:])"
      ],
      "metadata": {
        "id": "HLp_-3urc2hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO**: NODE2VEC\n",
        "\n",
        "Now you can try to implement **second-order biased random walks** like in node2vec.\n",
        "\n",
        "For each node $v_i$ in the walk, keep track of its predecessor $v_{i-1}$\n",
        "The neighbors of $v_i$ are assigned non-uniform probabilities (unnormalized):\n",
        "* The predecessor $v_{i-1}$ is assigned weight $1/p$ (return parameter)\n",
        "* Nodes that are *not* neighbors of $v_{i-1}$ are assigned weight $1/q$ (walk-away parameter)\n",
        "* Other neighbors of $v_i$ are assigned weight $1$\n",
        "\n",
        "Normalized weights give the distribution of the node to visit after $v_i$"
      ],
      "metadata": {
        "id": "_-taAoiXlMxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement this function to generate positive examples\n",
        "# It takes the graph, the length of the walks, the number of walks\n",
        "# to simulate from each node of the graph, the return parameter p\n",
        "# and the walk-away parameter q\n",
        "def positive_samples_so(G, length=5, n_walks=10, p=1, q=2):\n",
        "  # YOUR CODE HERE\n",
        "  return ..."
      ],
      "metadata": {
        "id": "SF_thXTL-nBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_3 = nn.Embedding(num_embeddings=G.number_of_nodes(), embedding_dim=16)\n",
        "\n",
        "# Initialize with uniform([0,1))\n",
        "emb_3.weight.data = torch.rand(size=emb_3.weight.data.shape)\n",
        "\n",
        "pos_edge_index = positive_samples_so(G, length=5, n_walks=10, p=1, q=2)\n",
        "neg_edge_index = negative_samples(G, 300)\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "# Generate the positive and negative labels\n",
        "pos_label = torch.ones(pos_edge_index.shape[1], )\n",
        "neg_label = torch.zeros(neg_edge_index.shape[1], )\n",
        "\n",
        "# Concat positive and negative labels into one tensor\n",
        "train_label = torch.cat([pos_label, neg_label], dim=0)\n",
        "n = len(train_label)\n",
        "\n",
        "# Concat positive and negative edges into one tensor\n",
        "# Since the network is very small, we do not split the edges into val/test sets\n",
        "train_edge = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
        "\n",
        "# Shuffle\n",
        "perm = torch.randperm(n)\n",
        "train_edge = train_edge[:, perm]\n",
        "train_label = train_label[perm]\n",
        "\n",
        "train(emb_3, loss_fn, train_label, train_edge)"
      ],
      "metadata": {
        "id": "el8OgUNVBNSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize learned embeddings\n",
        "visualize_emb(emb_3)"
      ],
      "metadata": {
        "id": "HB5tbww0dbjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = emb_3.weight.detach().numpy()\n",
        "y = np.zeros(X.shape[0])\n",
        "for i in range(G.number_of_nodes()):\n",
        "  y[i] = G.nodes[i]['club'] == 'Mr. Hi'\n",
        "\n",
        "clf = LogisticRegression(random_state=0).fit(X[:27], y[:27])\n",
        "clf.score(X[27:], y[27:])"
      ],
      "metadata": {
        "id": "VnyRc50AdebE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Node Classification with Graph Neural Networks"
      ],
      "metadata": {
        "id": "JGf-B9EBUD9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we will implement a Graph Convolutional Neural Network using PyTorch Geometric.\n",
        "\n",
        "Some (more) imports first:"
      ],
      "metadata": {
        "id": "tbzt1m-loVyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from ogb.nodeproppred import PygNodePropPredDataset\n",
        "\n",
        "from torch_geometric.datasets import TUDataset\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "6w7sVj5tUCzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check you are on GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print (device)"
      ],
      "metadata": {
        "id": "YbDgEAk7Up2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seeding\n",
        "seed = 42\n",
        "\n",
        "def seed_everything(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "seed_everything(seed)"
      ],
      "metadata": {
        "id": "Ee0OCAt1U1Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The dataset"
      ],
      "metadata": {
        "id": "8A_q8jytVR2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Open Graph Benchmark (OGB) is a collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs. Its datasets are automatically downloaded, processed, and split using the OGB Data Loader. The model performance can also be evaluated by using the OGB Evaluator in a unified manner."
      ],
      "metadata": {
        "id": "cPKz9HbRXw_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " The ogbn-arxiv dataset is a directed graph, representing the citation network between all Computer Science (CS) arXiv papers indexed by MAG. Each node is an arXiv paper and each directed edge indicates that one paper cites another one. Each paper comes with a 128-dimensional feature vector obtained by averaging the embeddings of words in its title and abstract.\n",
        "\n",
        "The **node classification** task is to predict the 40 subject areas of arXiv CS papers, e.g., cs.AI, cs.LG, and cs.OS, which are manually determined (i.e., labeled) by the paper's authors and arXiv moderators."
      ],
      "metadata": {
        "id": "1-d0XQ-6o4Dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = 'ogbn-arxiv'\n",
        "dataset = PygNodePropPredDataset(name=dataset_name,\n",
        "                                 root='./arxiv',\n",
        "                                 transform=T.ToSparseTensor())\n"
      ],
      "metadata": {
        "id": "cke5Xy67WfCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just one graph\n",
        "print(len(dataset))\n",
        "\n",
        "G = dataset[0]\n",
        "\n",
        "print(G)\n",
        "\n",
        "print(G.num_features)\n",
        "\n",
        "print(dataset.num_classes)"
      ],
      "metadata": {
        "id": "Yfz0mkqFbkvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's important to understand our data. The input to the network will be the node features.."
      ],
      "metadata": {
        "id": "Zav9qvUuuq2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G.x.shape"
      ],
      "metadata": {
        "id": "8cP8FBW2unDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...but also the graph connectivity:"
      ],
      "metadata": {
        "id": "2-5sMctNvCN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G.adj_t.shape"
      ],
      "metadata": {
        "id": "OkV4xTD0u4Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G.adj_t"
      ],
      "metadata": {
        "id": "vTGDB6-UvGLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The model\n",
        "\n",
        "![test](https://drive.google.com/uc?id=128AuYAXNXGg7PIhJJ7e420DoPWKb-RtL)"
      ],
      "metadata": {
        "id": "_o22LZWFkf_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO:** implement the Graph Convolutional Neural Network outlined above, using torch geometric's implementation of the graph convolution operator as the main building block: [GCNConv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GCNConv.html)"
      ],
      "metadata": {
        "id": "2Wc60Tpmq8jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# input dim: the number of node features\n",
        "# hidden dim: number of channels, fixed from the output of the first GCN block to the input of the last one\n",
        "# output dim: the number of classes\n",
        "# num_layers: how many times the first block in the picture above is repeated\n",
        "# dropout: dropout parameter\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
        "                 dropout):\n",
        "\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        # Useful stuff from torch.nn:\n",
        "        # torch.nn.ModuleList to define lists of modules\n",
        "        # torch.nn.BatchNorm1d\n",
        "        # torch.nn.LogSoftmax\n",
        "        # relu and dropout from torch.nn.functional\n",
        "\n",
        "    def forward(self, x, adj_t):\n",
        "        # YOUR CODE HERE\n",
        "        return ..."
      ],
      "metadata": {
        "id": "9ay0tjJWj7da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function implements a training epoch:"
      ],
      "metadata": {
        "id": "TbUnBFqZtpHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data, train_idx, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    loss = 0\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.adj_t)\n",
        "    loss = loss_fn(out[train_idx], data.y[train_idx].reshape(-1))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "CWrTmU2imCvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a function to evaluate the model:"
      ],
      "metadata": {
        "id": "dSEtQinltrW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test(model, data, split_idx, evaluator):\n",
        "    model.eval()\n",
        "\n",
        "    out = model(data.x, data.adj_t)\n",
        "\n",
        "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "    train_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['train']],\n",
        "        'y_pred': y_pred[split_idx['train']],\n",
        "    })['acc']\n",
        "    valid_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['valid']],\n",
        "        'y_pred': y_pred[split_idx['valid']],\n",
        "    })['acc']\n",
        "    test_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['test']],\n",
        "        'y_pred': y_pred[split_idx['test']],\n",
        "    })['acc']\n",
        "\n",
        "    return train_acc, valid_acc, test_acc"
      ],
      "metadata": {
        "id": "EEFqeVILmLKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some suggested hyperparmeters:"
      ],
      "metadata": {
        "id": "wXP-3mKLtylI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    'num_layers': 3,\n",
        "    'hidden_dim': 256,\n",
        "    'dropout': 0.2,\n",
        "    'lr': 0.05,\n",
        "    'epochs': 100,\n",
        "}"
      ],
      "metadata": {
        "id": "dUneJIUOmTPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split data for training/validation/testing and prepare our model:"
      ],
      "metadata": {
        "id": "XEXBtSsLvr7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G = G.to(device)\n",
        "split_idx = dataset.get_idx_split()\n",
        "train_idx = split_idx['train'].to(device)\n",
        "\n",
        "model = GCN(G.num_features, args['hidden_dim'],\n",
        "            dataset.num_classes, args['num_layers'],\n",
        "            args['dropout']).to(device)\n",
        "evaluator = Evaluator(name='ogbn-arxiv')"
      ],
      "metadata": {
        "id": "a6ij-LqRmV0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time for training:"
      ],
      "metadata": {
        "id": "De3dv3MVv2Mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
        "loss_fn = F.nll_loss # negative log likelihood\n",
        "\n",
        "best_model = None\n",
        "best_valid_acc = 0\n",
        "\n",
        "for epoch in range(1, 1 + args[\"epochs\"]):\n",
        "  loss = train(model, G, train_idx, optimizer, loss_fn)\n",
        "  result = test(model, G, split_idx, evaluator)\n",
        "  train_acc, valid_acc, test_acc = result\n",
        "  if valid_acc > best_valid_acc:\n",
        "      best_valid_acc = valid_acc\n",
        "      best_model = copy.deepcopy(model)\n",
        "  print(f'Epoch: {epoch:02d}, '\n",
        "        f'Loss: {loss:.4f}, '\n",
        "        f'Train: {100 * train_acc:.2f}%, '\n",
        "        f'Valid: {100 * valid_acc:.2f}% ')"
      ],
      "metadata": {
        "id": "L_4SEpgTmY2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how we did on the test data"
      ],
      "metadata": {
        "id": "D_rd67OJv9Ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_result = test(best_model, G, split_idx, evaluator)\n",
        "train_acc, valid_acc, test_acc = best_result\n",
        "print(f'Best model: '\n",
        "      f'Test: {100 * test_acc:.2f}%')"
      ],
      "metadata": {
        "id": "M74ahsEGmhMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9p-EqH27qZMM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}